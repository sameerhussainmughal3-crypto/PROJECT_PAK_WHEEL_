# Pak_Wheels_Project
 Projects For Cloud Data Engineering 
 # ğŸš— PakWheels Car Data Scraper + ETL Pipeline + Streamlit Dashboard

This project is a complete end-to-end **Data Engineering Pipeline** that scrapes data from **Pakwheels.com**, cleans and transforms it using Python, stores the results into **CSV & SQL Server**, and visualizes the insights through a **Streamlit Dashboard**.

---

## ğŸ”½ 1. Scrape Data from PakWheels
- Scraping using BeautifulSoup / Selenium
- Extract fields:
  - Car Title  
  - Model  
  - Price  
  - Mileage  
  - City  
  - Description  

---

## ğŸ 2. Load Raw Data using Python
- Convert scraped data into Pandas DataFrame  
- Save as **raw_data.csv**

---

## ğŸ”§ 3. Data Cleaning & Transformation
Using:
- **Pandas**
- **NumPy**
- **Matplotlib**

Cleaning includes:
- Removing null/duplicate rows  
- Standardizing price & mileage  
- Extracting numerical values  
- Creating new columns  

Output â†’ **clean_data.csv**

---

## ğŸ—„ï¸ 4. Load into SQL Server
Load cleaned CSV into SQL Server using:
- `pyodbc`
- SQL Server Management Studio (SSMS)

---

## ğŸ“Š 5. Data Visualization (Streamlit)
Interactive dashboard built using Streamlit:
- Search filters  
- Price insights  
- Mileage comparison  
- City-wise distribution  
- Dataset table view  

Run:
```bash
streamlit run app.py
ğŸ“¦ PakWheels-ETL-Pipeline
â”œâ”€â”€ scrape.py                # Scraping script
â”œâ”€â”€ transform.py             # Cleaning + transformation
â”œâ”€â”€ load_sql.py              # SQL Server loader
â”œâ”€â”€ app.py                   # Streamlit dashboard
â”œâ”€â”€ raw_data.csv             # Raw scraped data
â”œâ”€â”€ clean_data.csv           # Cleaned file
â”œâ”€â”€ requirements.txt         # Dependencies
â””â”€â”€ README.md                # Documentation


